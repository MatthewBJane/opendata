<!DOCTYPE html><html lang="en-US"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=Edge"><link rel="shortcut icon" href="https://nivlab.github.io/opendata/favicon.ico" type="image/x-icon"><link rel="stylesheet" href="https://nivlab.github.io/opendata/assets/css/just-the-docs-default.css"> <script type="text/javascript" src="https://nivlab.github.io/opendata/assets/js/vendor/lunr.min.js"></script> <script type="text/javascript" src="https://nivlab.github.io/opendata/assets/js/just-the-docs.js"></script><meta name="viewport" content="width=device-width, initial-scale=1"><title>Behavior | OpenData</title><meta name="generator" content="Jekyll v4.2.0" /><meta property="og:title" content="Behavior" /><meta property="og:locale" content="en_US" /><meta name="description" content="A Jekyll theme for documentation" /><meta property="og:description" content="A Jekyll theme for documentation" /><link rel="canonical" href="https://nivlab.github.io/opendata/docs/datasets/behavior/" /><meta property="og:url" content="https://nivlab.github.io/opendata/docs/datasets/behavior/" /><meta property="og:site_name" content="OpenData" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Behavior" /> <script type="application/ld+json"> {"description":"A Jekyll theme for documentation","headline":"Behavior","url":"https://nivlab.github.io/opendata/docs/datasets/behavior/","@type":"WebPage","@context":"https://schema.org"}</script><body> <svg xmlns="http://www.w3.org/2000/svg" style="display: none;"> <symbol id="svg-link" viewBox="0 0 24 24"><title>Link</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"><title>Search</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"><title>Menu</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"><title>Expand</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"><polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"><title>Document</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"><path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> </svg><div class="side-bar"><div class="site-header"> <a href="https://nivlab.github.io/opendata/" class="site-title lh-tight"> OpenData </a> <a href="#" id="menu-button" class="site-button"> <svg viewBox="0 0 24 24" class="icon"><use xlink:href="#svg-menu"></use></svg> </a></div><nav role="navigation" aria-label="Main" id="site-nav" class="site-nav"><ul class="nav-list"><li class="nav-list-item"><a href="https://nivlab.github.io/opendata/" class="nav-list-link">Home</a><li class="nav-list-item active"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="https://nivlab.github.io/opendata/docs/datasets" class="nav-list-link">Datasets</a><ul class="nav-list "><li class="nav-list-item active"><a href="https://nivlab.github.io/opendata/docs/datasets/behavior/" class="nav-list-link active">Behavior</a><li class="nav-list-item "><a href="https://nivlab.github.io/opendata/docs/datasets/psychiatry/" class="nav-list-link">Psychiatry</a><li class="nav-list-item "><a href="https://nivlab.github.io/opendata/docs/datasets/surveys/" class="nav-list-link">Surveys</a></ul><li class="nav-list-item"><a href="https://nivlab.github.io/opendata/docs/databases/" class="nav-list-link">Databases</a></ul></nav><footer class="site-footer"> This site uses <a href="https://github.com/pmarsceill/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll.</footer></div><div class="main" id="top"><div id="main-header" class="main-header"><div class="search"><div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search OpenData" aria-label="Search OpenData" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label></div><div id="search-results" class="search-results"></div></div><nav aria-label="Auxiliary" class="aux-nav"><ul class="aux-nav-list"><li class="aux-nav-list-item"> <a href="//github.com/nivlab/opendata" class="site-button" > OpenData on GitHub </a></ul></nav></div><div id="main-content-wrap" class="main-content-wrap"><nav aria-label="Breadcrumb" class="breadcrumb-nav"><ol class="breadcrumb-nav-list"><li class="breadcrumb-nav-list-item"><a href="https://nivlab.github.io/opendata/docs/datasets">Datasets</a><li class="breadcrumb-nav-list-item"><span>Behavior</span></ol></nav><div id="main-content" class="main-content" role="main"><h1 class="no_toc" id="behavior"> <a href="#behavior" aria-labelledby="behavior" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Behavior</h1><h2 class="no_toc text-delta" id="table-of-contents"> <a href="#table-of-contents" aria-labelledby="table-of-contents" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Table of contents</h2><ol id="markdown-toc"><li><a href="#decisions-from-description" id="markdown-toc-decisions-from-description">Decisions from Description</a><ol><li><a href="#glockner--pachur-2012" id="markdown-toc-glockner--pachur-2012">Glockner &amp; Pachur (2012)</a><li><a href="#erev-et-al-2017" id="markdown-toc-erev-et-al-2017">Erev et al. (2017)</a><li><a href="#frey-et-al-2017" id="markdown-toc-frey-et-al-2017">Frey et al. (2017)</a><li><a href="#wulff-et-al-2018" id="markdown-toc-wulff-et-al-2018">Wulff et al. (2018)</a></ol><li><a href="#reinforcement-learning" id="markdown-toc-reinforcement-learning">Reinforcement Learning</a><ol><li><a href="#klein-et-al-2017" id="markdown-toc-klein-et-al-2017">Klein et al. (2017)</a><li><a href="#lefebvre-et-al-2017" id="markdown-toc-lefebvre-et-al-2017">Lefebvre et al. (2017)</a><li><a href="#swart-et-al-2017" id="markdown-toc-swart-et-al-2017">Swart et al. (2017)</a><li><a href="#correa-et-al-2018" id="markdown-toc-correa-et-al-2018">Correa et al. (2018)</a><li><a href="#swart-et-al-2018" id="markdown-toc-swart-et-al-2018">Swart et al. (2018)</a><li><a href="#wu-et-al-2018" id="markdown-toc-wu-et-al-2018">Wu et al. (2018)</a><li><a href="#ballard-et-al-2019" id="markdown-toc-ballard-et-al-2019">Ballard et al. (2019)</a><li><a href="#moran-et-al-2019" id="markdown-toc-moran-et-al-2019">Moran et al. (2019)</a><li><a href="#zhu-et-al-2019" id="markdown-toc-zhu-et-al-2019">Zhu et al. (2019)</a></ol><li><a href="#eye-tracking" id="markdown-toc-eye-tracking">Eye-tracking</a><ol><li><a href="#wise-et-al-2019" id="markdown-toc-wise-et-al-2019">Wise et al. (2019)</a><li><a href="#thomas-et-al-2019" id="markdown-toc-thomas-et-al-2019">Thomas et al. (2019)</a></ol></ol><hr /><h2 id="decisions-from-description"> <a href="#decisions-from-description" aria-labelledby="decisions-from-description" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Decisions from Description</h2><h3 id="glockner--pachur-2012"> <a href="#glockner--pachur-2012" aria-labelledby="glockner--pachur-2012" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Glockner &amp; Pachur (2012)</h3><p><em>Cognitive models of risky choice: Parameter stability and predictive accuracy of prospect theory</em></p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Publication(s): https://doi.org/10.1016/j.cognition.2011.12.002
Data repository: https://osf.io/7khwj/
</code></pre></div></div><p>Choice data from 66 participants who completed two series of a gambles over a 1 week period. Suitable for studies of test-retest reliability.</p><h3 id="erev-et-al-2017"> <a href="#erev-et-al-2017" aria-labelledby="erev-et-al-2017" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Erev et al. (2017)</h3><p><em>From anomalies to forecasts: Toward a descriptive model of decisions under risk, under ambiguity, and from experience.</em></p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Publication(s): http://doi.org/10.1037/rev0000062
Data repository: https://zenodo.org/record/845873#.WeDg9GhSw2x
</code></pre></div></div><p>The raw data from a choice prediction competition for decisions under risk, under ambiguity, and from experience. The data includes 510,750 consequential choices of human decision makers choosing between two risky and/or uncertain prospects with up to 10 possible outcomes each.</p><h3 id="frey-et-al-2017"> <a href="#frey-et-al-2017" aria-labelledby="frey-et-al-2017" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Frey et al. (2017)</h3><p><em>Risk preference shares the psychometric structure of major psychological traits</em></p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Publication(s): http://doi.org/10.1126/sciadv.1701381
Data repository: https://osf.io/rce7g/
</code></pre></div></div><p>The dataset from the Basel-Berlin Risk Study involving the study of 1507 healthy adults completing 39 risk-taking measures, with a subsample of 109 participants completing a retest session after 6 months.</p><h3 id="wulff-et-al-2018"> <a href="#wulff-et-al-2018" aria-labelledby="wulff-et-al-2018" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Wulff et al. (2018)</h3><p><em>A meta-analytic review of two modes of learning and the description-experience gap.</em></p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Publication(s): https://doi.org/10.1037/bul0000115
Data repository: https://zenodo.org/record/1491449
</code></pre></div></div><p>The aggregated data from 28 publications of experiments studying decisions from description and experience.</p><hr /><h2 id="reinforcement-learning"> <a href="#reinforcement-learning" aria-labelledby="reinforcement-learning" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Reinforcement Learning</h2><h3 id="klein-et-al-2017"> <a href="#klein-et-al-2017" aria-labelledby="klein-et-al-2017" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Klein et al. (2017)</h3><p><em>Learning relative values in the striatum induces violations of normative decision making</em></p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Publication(s): https://doi.org/10.1038/ncomms16033
Data repository: https://www.nature.com/articles/s41467-019-10718-8#Sec19
</code></pre></div></div><p>The data from 75 participants in a 2-arm bandit task with novel choice contexts introduced throughout the task. Behavior on the task shows agents learn how good an option is relative to an option with which it had previously been paired.</p><h3 id="lefebvre-et-al-2017"> <a href="#lefebvre-et-al-2017" aria-labelledby="lefebvre-et-al-2017" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Lefebvre et al. (2017)</h3><p><em>Behavioural and neural characterization of optimistic reinforcement learning</em></p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Publication(s): https://doi.org/10.1038/s41562-017-0067
Data repository: https://figshare.com/articles/dataset/Behavioral_data_and_data_extraction_code/4265408/1
</code></pre></div></div><p>The behavior from 85 participants who performed a simple 2-arm bandit task.</p><h3 id="swart-et-al-2017"> <a href="#swart-et-al-2017" aria-labelledby="swart-et-al-2017" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Swart et al. (2017)</h3><p><em>Catecholaminergic challenge uncovers distinct Pavlovian and instrumental mechanisms of motivated (in)action</em></p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Publications: https://elifesciences.org/articles/22169/
Data repository: https://elifesciences.org/articles/22169/figures#SD1-data
</code></pre></div></div><p>106 participants on the Pavlovian Instrumental Transfer task.</p><h3 id="correa-et-al-2018"> <a href="#correa-et-al-2018" aria-labelledby="correa-et-al-2018" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Correa et al. (2018)</h3><p><em>How the Level of Reward Awareness Changes the Computational and Electrophysiological Signatures of Reinforcement Learning</em></p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Publication(s): https://doi.org/10.1523/JNEUROSCI.0457-18.2018
Data repository: https://figshare.com/articles/Codes_and_Data_-_Correa_et_al_JNeuro_2018/7987100
</code></pre></div></div><p>A study investigating the effects of stimulus visibility on reward learning and choice.</p><h3 id="swart-et-al-2018"> <a href="#swart-et-al-2018" aria-labelledby="swart-et-al-2018" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Swart et al. (2018)</h3><p><em>Frontal network dynamics reflect neurocomputational mechanisms for reducing maladaptive biases in motivated action</em></p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Publications(s): https://doi.org/10.1371/journal.pbio.2005979
Data repository: https://data.donders.ru.nl/collections/di/dccn/DSC_3017033.03_624?0
</code></pre></div></div><p>34 participants on the Pavlovian Instrumental Transfer task.</p><h3 id="wu-et-al-2018"> <a href="#wu-et-al-2018" aria-labelledby="wu-et-al-2018" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Wu et al. (2018)</h3><p><em>Generalization guides human exploration in vast decision spaces</em></p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Publication(s): https://doi.org/10.1038/s41562-018-0467-4
Data repository: https://github.com/charleywu/gridsearch
</code></pre></div></div><p>Study of human exploration in environments with spatially correlated patterns of rewards.</p><h3 id="ballard-et-al-2019"> <a href="#ballard-et-al-2019" aria-labelledby="ballard-et-al-2019" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Ballard et al. (2019)</h3><p><em>Hippocampal pattern separation supports reinforcement learning</em></p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Publication(s): https://doi.org/10.1038/s41467-019-08998-1
Data repository: https://openneuro.org/datasets/ds001590
</code></pre></div></div><p>The behavior and fMRI data from 32 participants who performed a configural reinforcement learning task.</p><h3 id="moran-et-al-2019"> <a href="#moran-et-al-2019" aria-labelledby="moran-et-al-2019" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Moran et al. (2019)</h3><p><em>Retrospective Model-Based inference Guides Model-Free Credit Assignment</em></p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Publication(s): https://doi.org/10.1038/s41467-019-08662-8
Data repository: https://osf.io/8j7yf/
</code></pre></div></div><p>Study of MB retrospective-inference, wherein MB system resolves uncertainty present at the time of choice thereby guiding an MF credit-assignment.</p><h3 id="zhu-et-al-2019"> <a href="#zhu-et-al-2019" aria-labelledby="zhu-et-al-2019" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Zhu et al. (2019)</h3><p><em>Patients with basal ganglia damage show preserved learning in an economic game</em></p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Publications(s): https://doi.org/10.1038/s41467-019-08766-1
Data repository: https://osf.io/4x3nf/
</code></pre></div></div><p>Study of the behavior of patients with focal lesions to either basal ganglia or orbitofrontal cortex in a multi-strategy competitive game known to engage these regions. They find that whereas OFC patients are significantly impaired, BG patients show intact learning in the economic game. By contrast, when information about the strategic context is absent, both cohorts are significantly impaired.</p><hr /><h2 id="eye-tracking"> <a href="#eye-tracking" aria-labelledby="eye-tracking" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Eye-tracking</h2><h3 id="wise-et-al-2019"> <a href="#wise-et-al-2019" aria-labelledby="wise-et-al-2019" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Wise et al. (2019)</h3><p><em>A computational account of threat-related attentional bias</em></p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Publications(s): https://doi.org/10.1371/journal.pcbi.1007341
Data repository: https://osf.io/b4e72/
</code></pre></div></div><p>Measures of visual attention through eye-tracking of threatening stimuli in aversive reinforcement learning task.</p><h3 id="thomas-et-al-2019"> <a href="#thomas-et-al-2019" aria-labelledby="thomas-et-al-2019" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Thomas et al. (2019)</h3><p><em>Gaze bias differences capture individual choice behaviour</em></p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Publications(s): https://doi.org/10.1038/s41562-019-0584-8
Data repository: http://www.github.com/glamlab/gaze-bias-differences
</code></pre></div></div><p>An investigation of the strength of the relationship between eye gaze and choice across four different simple choice experiments. They report that an association between gaze and choice is present for most individuals, but differs considerably in strength.</p><hr><footer><p><a href="#top" id="back-to-top">Back to top</a></p><p class="text-small text-grey-dk-000 mb-0">Copyright &copy; 2019-2021 Niv Lab. Distributed by an <a href="https://github.com/nivlab/opendata/LICENSE">MIT license.</a></p><div class="d-flex mt-2"><p class="text-small text-grey-dk-000 mb-0"> <a href="https://github.com/nivlab/opendata/tree/docs/docs/datasets/behavior.md" id="edit-this-page">Edit this page on GitHub</a></p></div></footer></div></div><div class="search-overlay"></div></div>
